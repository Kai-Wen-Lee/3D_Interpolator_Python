{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6989970c-008b-4a68-aeaf-20c79057d5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import netCDF4\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7cf46c-301b-4188-a4bc-340abb7bdd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 05:04:10,293 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='C:\\\\Users\\\\Kai Wen Lee\\\\Documents\\\\Journal-KW-MASTER\\\\NOB\\\\JupyterNotebooks\\\\Mesh\\\\corsetofine\\\\flow0000.nc', lease_id='40323e6fb1c94599b724d89c8be732f6'. This can happen if the Lock or Semaphore timed out before.\n",
      "2025-01-05 05:04:10,341 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='C:\\\\Users\\\\Kai Wen Lee\\\\Documents\\\\Journal-KW-MASTER\\\\NOB\\\\JupyterNotebooks\\\\Mesh\\\\corsetofine\\\\flow0000.nc', lease_id='381a071f669440b2aacda85d46058b61'. This can happen if the Lock or Semaphore timed out before.\n",
      "2025-01-05 05:20:53,072 - tornado.application - ERROR - Uncaught exception GET /status/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:8787', method='GET', uri='/status/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tornado\\websocket.py\", line 938, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tornado\\web.py\", line 3301, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\server\\views\\ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2025-01-05 05:21:39,700 - distributed.dashboard.components.scheduler - ERROR - 'setitem-store-map-d6a622924974b6982057d62eee44f433'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\utils.py\", line 811, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2630, in update_layout\n",
      "    x = max(xs[dep] for dep in dependencies[tg]) + 1\n",
      "        ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2630, in <genexpr>\n",
      "    x = max(xs[dep] for dep in dependencies[tg]) + 1\n",
      "            ~~^^^^^\n",
      "KeyError: 'setitem-store-map-d6a622924974b6982057d62eee44f433'\n",
      "2025-01-05 05:21:39,703 - distributed.dashboard.components.scheduler - ERROR - 'setitem-store-map-d6a622924974b6982057d62eee44f433'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\utils.py\", line 811, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 4686, in tg_graph_doc\n",
      "    tg_graph.update()\n",
      "    ~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\core\\property\\validation.py\", line 95, in func\n",
      "    return input_function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2679, in update\n",
      "    self.nodes_layout, self.arrows_layout = self.update_layout()\n",
      "                                            ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\core\\property\\validation.py\", line 95, in func\n",
      "    return input_function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\utils.py\", line 811, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2630, in update_layout\n",
      "    x = max(xs[dep] for dep in dependencies[tg]) + 1\n",
      "        ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2630, in <genexpr>\n",
      "    x = max(xs[dep] for dep in dependencies[tg]) + 1\n",
      "            ~~^^^^^\n",
      "KeyError: 'setitem-store-map-d6a622924974b6982057d62eee44f433'\n",
      "2025-01-05 05:21:39,705 - tornado.application - ERROR - Uncaught exception GET /groups (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='localhost:8787', method='GET', uri='/groups', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tornado\\web.py\", line 1790, in _execute\n",
      "    result = await result\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\server\\views\\doc_handler.py\", line 54, in get\n",
      "    session = await self.get_session()\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\server\\views\\session_handler.py\", line 145, in get_session\n",
      "    session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\server\\contexts.py\", line 240, in create_session_if_needed\n",
      "    self._application.initialize_document(doc)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\application\\application.py\", line 190, in initialize_document\n",
      "    h.modify_document(doc)\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\application\\handlers\\function.py\", line 140, in modify_document\n",
      "    self._func(doc)\n",
      "    ~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\utils.py\", line 811, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 4686, in tg_graph_doc\n",
      "    tg_graph.update()\n",
      "    ~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\core\\property\\validation.py\", line 95, in func\n",
      "    return input_function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2679, in update\n",
      "    self.nodes_layout, self.arrows_layout = self.update_layout()\n",
      "                                            ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bokeh\\core\\property\\validation.py\", line 95, in func\n",
      "    return input_function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\utils.py\", line 811, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2630, in update_layout\n",
      "    x = max(xs[dep] for dep in dependencies[tg]) + 1\n",
      "        ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\dashboard\\components\\scheduler.py\", line 2630, in <genexpr>\n",
      "    x = max(xs[dep] for dep in dependencies[tg]) + 1\n",
      "            ~~^^^^^\n",
      "KeyError: 'setitem-store-map-d6a622924974b6982057d62eee44f433'\n"
     ]
    }
   ],
   "source": [
    "#localhost:8787/status\n",
    "client=Client(n_workers=16,\n",
    "               threads_per_worker=2,\n",
    "               memory_target_fraction=0.95,\n",
    "               memory_limit='1GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11ff975-073d-479d-9a63-44839977ec08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_old = netCDF4.Dataset('geometry_old.nc', 'r')\n",
    "zu_coarse = da.from_array(g_old['z_uz'])\n",
    "zp_coarse = da.from_array(g_old['z_p'])\n",
    "dz_coarse = da.from_array(g_old['delta_z_p'])\n",
    "rp_coarse = da.from_array(g_old['r_p'])\n",
    "rw_coarse = da.from_array(g_old['r_ur'])\n",
    "dr_coarse = da.from_array(g_old['delta_r_p'])\n",
    "dphi_coarse = da.from_array(g_old['delta_phi'])\n",
    "\n",
    "dimz_coarse = len(g_old.dimensions['dim_z'])\n",
    "dimphi_coarse = len(g_old.dimensions['dim_phi'])\n",
    "dimr_coarse = len(g_old.dimensions['dim_r'])\n",
    "\n",
    "height_coarse = da.max(zp_coarse)\n",
    "phi_coarse = da.arange(dimphi_coarse) * dphi_coarse - np.pi - dphi_coarse - dphi_coarse / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4546831-4dab-46b6-bec1-9f89a9923dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_new = netCDF4.Dataset('geometry.nc', 'r')\n",
    "zu_fine = da.from_array(g_new['z_uz'])\n",
    "zp_fine = da.from_array(g_new['z_p'])\n",
    "dz_fine = da.from_array(g_new['delta_z_p'])\n",
    "rp_fine = da.from_array(g_new['r_p'])\n",
    "rw_fine = da.from_array(g_new['r_ur'])\n",
    "dr_fine = da.from_array(g_new['delta_r_p'])\n",
    "dphi_fine = da.from_array(g_new['delta_phi'])\n",
    "\n",
    "dimz_fine = len(g_new.dimensions['dim_z'])\n",
    "dimphi_fine = len(g_new.dimensions['dim_phi'])\n",
    "dimr_fine = len(g_new.dimensions['dim_r'])\n",
    "\n",
    "height_fine = da.max(zp_fine)\n",
    "phi_fine = da.arange(dimphi_fine) * dphi_fine - np.pi - dphi_fine - dphi_fine / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d1c115a-5374-4f81-a5e3-0c7240d2c556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file='flow0037.nc'\n",
    "# Read data from coarse mesh\n",
    "f_old = netCDF4.Dataset(file, 'r')\n",
    "step = f_old.variables['timestep'][:]\n",
    "time = f_old.variables['time'][:]\n",
    "gamma = f_old.variables['gamma'][:]\n",
    "Ra = f_old.variables['Ra'][:]\n",
    "Pr = f_old.variables['Pr'][:]\n",
    "Ro = f_old.variables['Ro'][:]\n",
    "\n",
    "temp_coarse = da.from_array(f_old['temp'])\n",
    "uz_coarse = da.from_array(f_old['uz'])\n",
    "uphi_coarse = da.from_array(f_old['uphi'])\n",
    "ur_coarse = da.from_array(f_old['ur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e5f89-cfc8-4c38-b0ce-a047d2c857a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76ee8a2-8cae-4792-9895-1bd586057518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<array, shape=(474,), dtype=float64, chunksize=(474,), chunktype=numpy.MaskedArray>\n",
      "dask.array<array, shape=(1538,), dtype=float64, chunksize=(1538,), chunktype=numpy.MaskedArray>\n",
      "(1538, 1538, 1028)\n",
      "dask.array<array, shape=(386, 474, 132), dtype=float64, chunksize=(356, 356, 132), chunktype=numpy.MaskedArray>\n"
     ]
    }
   ],
   "source": [
    "Z_coarse, R_coarse, Phi_coarse = da.meshgrid(zu_coarse,rp_coarse,phi_coarse)\n",
    "Z_fine, R_fine, Phi_fine = da.meshgrid(zu_fine,rp_fine,phi_fine)\n",
    "\n",
    "print(rp_coarse)\n",
    "print(rp_fine)\n",
    "print(Phi_fine.shape)\n",
    "print(temp_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0fba577-39ef-496f-99f7-2468b9beca8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spline(X, Y, T, sigma = 1.0):\n",
    "    n = min(len(X), len(Y))\n",
    "    if n <= 2:\n",
    "        print('X and Y must be arrays of 3 or more elements.')\n",
    "    if sigma != 1.0:\n",
    "        sigma = min(sigma, 0.001)\n",
    "    yp = np.zeros(2*n)\n",
    "    delx1 = X[1]-X[0]\n",
    "    dx1 = (Y[1]-Y[0])/delx1\n",
    "    nm1 = n-1\n",
    "    nmp = n+1\n",
    "    delx2 = X[2]-X[1]\n",
    "    delx12 = X[2]-X[0]\n",
    "    c1 = -(delx12+delx1)/(delx12*delx1)\n",
    "    c2 = delx12/(delx1*delx2)\n",
    "    c3 = -delx1/(delx12*delx2)\n",
    "    slpp1 = c1*Y[0]+c2*Y[1]+c3*Y[2]\n",
    "    deln = X[nm1]-X[nm1-1]\n",
    "    delnm1 = X[nm1-1]-X[nm1-2]\n",
    "    delnn = X[nm1]-X[nm1-2]\n",
    "    c1 = (delnn+deln)/(delnn*deln)\n",
    "    c2 = -delnn/(deln*delnm1)\n",
    "    c3 = deln/(delnn*delnm1)\n",
    "    slppn = c3*Y[nm1-2]+c2*Y[nm1-1]+c1*Y[nm1]\n",
    "    sigmap = sigma*nm1/(X[nm1]-X[0])\n",
    "    dels = sigmap*delx1\n",
    "    exps = np.exp(dels)\n",
    "    sinhs = 0.5*(exps-1/exps)\n",
    "    sinhin = 1/(delx1*sinhs)\n",
    "    diag1 = sinhin*(dels*0.5*(exps+1/exps)-sinhs)\n",
    "    diagin = 1/diag1\n",
    "    yp[0] = diagin*(dx1-slpp1)\n",
    "    spdiag = sinhin*(sinhs-dels)\n",
    "    yp[n] = diagin*spdiag\n",
    "    delx2 = X[1:]-X[:-1]\n",
    "    dx2 = (Y[1:]-Y[:-1])/delx2\n",
    "    dels = sigmap*delx2\n",
    "    exps = np.exp(dels)\n",
    "    sinhs = 0.5*(exps-1/exps)\n",
    "    sinhin = 1/(delx2*sinhs)\n",
    "    diag2 = sinhin*(dels*(0.5*(exps+1/exps))-sinhs)\n",
    "    diag2 = np.concatenate([np.array([0]), diag2[:-1]+diag2[1:]])\n",
    "    dx2nm1 = dx2[nm1-1]\n",
    "    dx2 = np.concatenate([np.array([0]), dx2[1:]-dx2[:-1]])\n",
    "    spdiag = sinhin*(sinhs-dels)\n",
    "    for i in range(1, nm1):\n",
    "        diagin = 1/(diag2[i]-spdiag[i-1]*yp[i+n-1])\n",
    "        yp[i] = diagin*(dx2[i]-spdiag[i-1]*yp[i-1])\n",
    "        yp[i+n] = diagin*spdiag[i]\n",
    "    diagin = 1/(diag1-spdiag[nm1-1]*yp[n+nm1-1])\n",
    "    yp[nm1] = diagin*(slppn-dx2nm1-spdiag[nm1-1]*yp[nm1-1])\n",
    "    for i in range(n-2, -1, -1):\n",
    "        yp[i] = yp[i]-yp[i+n]*yp[i+1]\n",
    "    m = len(T)\n",
    "    subs = np.repeat(nm1, m)\n",
    "    s = X[nm1]-X[0]\n",
    "    sigmap = sigma*nm1/s\n",
    "    j = 0\n",
    "    for i in range(1, nm1+1):\n",
    "        while T[j] < X[i]:\n",
    "            subs[j] = i\n",
    "            j += 1\n",
    "            if j == m:\n",
    "                break\n",
    "        if j == m:\n",
    "            break\n",
    "    subs1 = subs-1\n",
    "    del1 = T-X[subs1]\n",
    "    del2 = X[subs]-T\n",
    "    dels = X[subs]-X[subs1]\n",
    "    exps1 = np.exp(sigmap*del1)\n",
    "    sinhd1 = 0.5*(exps1-1/exps1)\n",
    "    exps = np.exp(sigmap*del2)\n",
    "    sinhd2 = 0.5*(exps-1/exps)\n",
    "    exps = exps1*exps\n",
    "    sinhs = 0.5*(exps-1/exps)\n",
    "    spl = (yp[subs]*sinhd1+yp[subs1]*sinhd2)/sinhs+((Y[subs]-yp[subs])*del1+(Y[subs1]-yp[subs1])*del2)/dels\n",
    "    if m == 1:\n",
    "        return spl[0]\n",
    "    else:\n",
    "        return spl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb1b06-067e-4d31-bf1d-14f31cad2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = da.zeros([12, 12, 12])\n",
    "print(test.shape)\n",
    "test[:, 0, 0] = spline(\n",
    "        da.array([1, 2, 3, 4, 5, 6]), \n",
    "        da.array([2, 2, 2, 4, 4, 4]), \n",
    "        da.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "    )\n",
    "test[0, :, 0] = spline(\n",
    "        da.array([1, 2, 3, 4, 5, 6]), \n",
    "        da.array([5, 5, 5, 4, 4, 4]), \n",
    "        da.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "    )\n",
    "test[0, 0, :] = spline(\n",
    "    da.array([1, 2, 3, 4, 5, 6]), \n",
    "    da.array([100, 200, 200, 400, 400, 400]), \n",
    "    da.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    ")\n",
    "print(test)\n",
    "#print(test.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348d296-a97b-4a60-8029-a13a5d9d7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testc=da.linspace(0,1,num=10)\n",
    "testf=da.linspace(0,1,num=100)\n",
    "testrng = da.random.default_rng()\n",
    "testvals = testrng.standard_normal(10)\n",
    "\n",
    "@dask.delayed\n",
    "def testfunc(cc,vals,ff):\n",
    "    return spline(cc,vals,ff)\n",
    "\n",
    "@dask.delayed\n",
    "def output(arr1,arr2,arr3):\n",
    "    test=da.zeros([100,100,100])\n",
    "    test[:,0,0]=arr1\n",
    "    test[0,:,0]=arr2\n",
    "    test[0,0,:]=arr3\n",
    "    return test\n",
    "    \n",
    "task1 =testfunc(testc,testvals,testf)\n",
    "task2 =testfunc(testc,testvals,testf)\n",
    "task3 =testfunc(testc,testvals,testf)\n",
    "combineheuhue = output(task1,task2,task3)\n",
    "\n",
    "# Combine the tasks and compute them in parallel\n",
    "results = combineheuhue.compute()\n",
    "\n",
    "# Print the shapes of the computed arrays\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e5a65a-74b4-45d4-8666-fb1c02676452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\client.py:3371: UserWarning: Sending large graph of size 184.26 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def convert_to_array(maskedarr):\n",
    "    computed_array=maskedarr.compute()\n",
    "    tempndarr = computed_array.data\n",
    "    return da.array(tempndarr)\n",
    "\n",
    "temp_coarse=convert_to_array(temp_coarse)\n",
    "rp_coarse=convert_to_array(rp_coarse)\n",
    "rp_fine=convert_to_array(rp_fine)\n",
    "\n",
    "phi_coarse=convert_to_array(phi_coarse)\n",
    "phi_fine=convert_to_array(phi_fine)\n",
    "\n",
    "zu_coarse=convert_to_array(zu_coarse)\n",
    "zu_fine=convert_to_array(zu_fine)\n",
    "\n",
    "temp_coarse=convert_to_array(temp_coarse)\n",
    "rp_coarse=convert_to_array(rp_coarse)\n",
    "rp_fine=convert_to_array(rp_fine)\n",
    "\n",
    "phi_coarse=convert_to_array(phi_coarse)\n",
    "phi_fine=convert_to_array(phi_fine)\n",
    "\n",
    "zu_coarse=convert_to_array(zu_coarse)\n",
    "zu_fine=convert_to_array(zu_fine)\n",
    "\n",
    "temp_coarse=convert_to_array(temp_coarse)\n",
    "rp_coarse=convert_to_array(rp_coarse)\n",
    "rp_fine=convert_to_array(rp_fine)\n",
    "\n",
    "phi_coarse=convert_to_array(phi_coarse)\n",
    "phi_fine=convert_to_array(phi_fine)\n",
    "\n",
    "zu_coarse=convert_to_array(zu_coarse)\n",
    "zu_fine=convert_to_array(zu_fine)\n",
    "\n",
    "uz_coarse=convert_to_array(uz_coarse)\n",
    "ur_coarse=convert_to_array(ur_coarse)\n",
    "uphi_coarse=convert_to_array(uphi_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ecc13da-2648-4028-965a-1d230dd697de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kai Wen Lee\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\distributed\\client.py:3371: UserWarning: Sending large graph of size 180.74 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1538, 1538, 1028)\n"
     ]
    }
   ],
   "source": [
    "@dask.delayed\n",
    "def splinewrapper(finearr,data,coarsearr):\n",
    "    return spline(finearr,data,coarsearr)\n",
    "\n",
    "@dask.delayed\n",
    "def output(arrz,arrr,arrphi):\n",
    "    arrout=da.zeros([dimz_fine,dimr_fine,dimphi_fine])\n",
    "    arrout[0,:,0]=arrz\n",
    "    arrout[0,0,:]=arrr\n",
    "    arrout[:,0,0]=arrphi\n",
    "    return arrout\n",
    "\n",
    "\n",
    "tempr =splinewrapper(rp_coarse,temp_coarse[0,:,0],rp_fine)\n",
    "tempphi =splinewrapper(phi_coarse,temp_coarse[0,0,:],phi_fine)\n",
    "tempz =splinewrapper(zu_coarse,temp_coarse[:,0,0],zu_fine)\n",
    "tempf = output(tempr,tempphi,tempz)\n",
    "\n",
    "# Combine the tasks and compute them in parallel\n",
    "temp_fine = tempf.compute()\n",
    "\n",
    "# Print the shapes of the computed arrays\n",
    "print(temp_fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e579cc-b223-43b4-9036-d94e75df9435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1538, 1538, 1028)\n"
     ]
    }
   ],
   "source": [
    "uzr =splinewrapper(rp_coarse,uz_coarse[0,:,0],rp_fine)\n",
    "uzphi =splinewrapper(phi_coarse,uz_coarse[0,0,:],phi_fine)\n",
    "uzz =splinewrapper(zu_coarse,uz_coarse[:,0,0],zu_fine)\n",
    "uzf = output(uzr,uzphi,uzz)\n",
    "\n",
    "# Combine the tasks and compute them in parallel\n",
    "uz_fine = uzf.compute()\n",
    "\n",
    "# Print the shapes of the computed arrays\n",
    "print(uz_fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91fca275-46e8-43f6-8bb6-ab2eac2e6f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1538, 1538, 1028)\n"
     ]
    }
   ],
   "source": [
    "urr =splinewrapper(rp_coarse,uz_coarse[0,:,0],rp_fine)\n",
    "urphi =splinewrapper(phi_coarse,uz_coarse[0,0,:],phi_fine)\n",
    "urz =splinewrapper(zu_coarse,uz_coarse[:,0,0],zu_fine)\n",
    "urf = output(uzr,uzphi,uzz)\n",
    "\n",
    "# Combine the tasks and compute them in parallel\n",
    "ur_fine = urf.compute()\n",
    "\n",
    "# Print the shapes of the computed arrays\n",
    "print(ur_fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a6da92-74ce-4b5d-b612-4057a1fc5e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1538, 1538, 1028)\n"
     ]
    }
   ],
   "source": [
    "uphir =splinewrapper(rp_coarse,uphi_coarse[0,:,0],rp_fine)\n",
    "uphiphi =splinewrapper(phi_coarse,uphi_coarse[0,0,:],phi_fine)\n",
    "uphiz =splinewrapper(zu_coarse,uphi_coarse[:,0,0],zu_fine)\n",
    "uphif = output(uzr,uzphi,uzz)\n",
    "\n",
    "# Combine the tasks and compute them in parallel\n",
    "uphi_fine = urf.compute()\n",
    "\n",
    "# Print the shapes of the computed arrays\n",
    "print(uphi_fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68b1d9a-b89c-4550-b76e-d5b3cf0776bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow file summary:\n",
      "<xarray.Dataset> Size: 78GB\n",
      "Dimensions:   (dim_0: 1538, dim_1: 1538, dim_2: 1028)\n",
      "Dimensions without coordinates: dim_0, dim_1, dim_2\n",
      "Data variables:\n",
      "    Ra        float64 8B ...\n",
      "    Pr        float64 8B ...\n",
      "    Ro        float64 8B ...\n",
      "    gamma     float64 8B ...\n",
      "    time      float64 8B ...\n",
      "    timestep  int32 4B ...\n",
      "    temp      (dim_0, dim_1, dim_2) float64 19GB dask.array<chunksize=(255, 255, 255), meta=np.ndarray>\n",
      "    uz        (dim_0, dim_1, dim_2) float64 19GB dask.array<chunksize=(255, 255, 255), meta=np.ndarray>\n",
      "    uphi      (dim_0, dim_1, dim_2) float64 19GB dask.array<chunksize=(255, 255, 255), meta=np.ndarray>\n",
      "    ur        (dim_0, dim_1, dim_2) float64 19GB dask.array<chunksize=(255, 255, 255), meta=np.ndarray>\n",
      "Comparison with course file:\n",
      "<xarray.Dataset> Size: 773MB\n",
      "Dimensions:   (dim_z: 386, dim_r: 474, dim_phi: 132)\n",
      "Dimensions without coordinates: dim_z, dim_r, dim_phi\n",
      "Data variables:\n",
      "    Ra        float64 8B ...\n",
      "    Pr        float64 8B ...\n",
      "    Ro        float64 8B ...\n",
      "    gamma     float64 8B ...\n",
      "    time      float64 8B ...\n",
      "    timestep  int32 4B ...\n",
      "    temp      (dim_z, dim_r, dim_phi) float64 193MB ...\n",
      "    ur        (dim_z, dim_r, dim_phi) float64 193MB ...\n",
      "    uphi      (dim_z, dim_r, dim_phi) float64 193MB ...\n",
      "    uz        (dim_z, dim_r, dim_phi) float64 193MB ...\n"
     ]
    }
   ],
   "source": [
    "#Write everything, need to use Xarrays for this\n",
    "import xarray as xr\n",
    "flow_coarse = xr.open_dataset(\"flow0037.nc\", engine=\"netcdf4\",format='netCDF4')\n",
    "flow_fine = xr.Dataset().chunk(chunks={\"auto\"})\n",
    "flow_fine['Ra']=flow_coarse.Ra\n",
    "flow_fine['Pr']=flow_coarse.Pr\n",
    "flow_fine['Ro']=flow_coarse.Ro\n",
    "flow_fine['gamma']=flow_coarse.gamma\n",
    "flow_fine['time']=flow_coarse.time\n",
    "flow_fine['timestep']=flow_coarse.timestep\n",
    "flow_fine['temp'] = xr.DataArray(temp_fine)\n",
    "flow_fine['uz'] = xr.DataArray(uz_fine)\n",
    "flow_fine['uphi'] = xr.DataArray(uphi_fine)\n",
    "flow_fine['ur'] = xr.DataArray(ur_fine) \n",
    "print('Flow file summary:')\n",
    "print(flow_fine)\n",
    "print('Comparison with course file:')\n",
    "print(flow_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "338d69af-4465-4dfc-b0bb-61dbafff5869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing\n"
     ]
    }
   ],
   "source": [
    "print('writing')\n",
    "encoding = {\"temp\": {\"zlib\": True, \"complevel\": 9},\n",
    "            \"ur\": {\"zlib\": True, \"complevel\": 9},\n",
    "            \"uphi\": {\"zlib\": True, \"complevel\": 9},\n",
    "            \"uz\": {\"zlib\": True, \"complevel\": 9}}\n",
    "flow_fine.to_netcdf(\"flow0000.nc\", format=\"NETCDF4\",engine=\"netcdf4\",mode=\"w\",encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e61b0-2e0f-484a-9e82-2a260e99a874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
